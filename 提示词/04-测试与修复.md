# 测试与修复指令

## 指令内容

```

```

## 指令含义

**核心原则：测试驱动质量，修复解决问题**

这个指令要求AI在开发完成后必须执行所有测试，当测试失败时要正确分析问题根源，优先修复业务逻辑代码中的实际问题，而不是简单地修改测试来通过验证。

## 适用场景

### 1. 功能开发完成后

- 新功能实现的验证
- 代码重构后的回归测试
- 性能优化后的功能验证

### 2. 问题修复验证

- Bug修复效果验证
- 安全漏洞修补验证
- 兼容性问题解决验证

### 3. 系统集成测试

- 模块间集成验证
- 第三方服务集成测试
- 端到端功能测试

## 测试执行流程

### 1. 测试准备阶段

```markdown
准备清单：
- [ ] 确认所有代码修改已完成
- [ ] 检查测试环境配置
- [ ] 准备测试数据
- [ ] 清理之前的测试残留
```

### 2. 测试执行阶段

```markdown
执行顺序：
1. 单元测试 (Unit Tests)
2. 集成测试 (Integration Tests)
3. 功能测试 (Functional Tests)
4. 性能测试 (Performance Tests)
5. 端到端测试 (E2E Tests)
```

### 3. 结果分析阶段

```markdown
分析维度：
- 测试通过率统计
- 失败测试分类
- 错误信息解读
- 影响范围评估
```

## 问题分析方法

### 失败原因分类

#### 1. 业务逻辑代码问题 (优先修复)

```markdown
典型表现：
- 功能实现不符合需求
- 算法逻辑错误
- 数据处理异常
- 边界条件处理不当
- 异常处理缺失
- 性能不达标

修复原则：
- 深入理解业务需求
- 修复根本问题
- 确保逻辑正确性
- 提升代码健壮性
```

#### 2. 测试代码问题 (次要修复)

```markdown
典型表现：
- 测试用例设计错误
- 测试数据不准确
- 测试环境配置问题
- 断言条件不合理
- 模拟数据过时

修复原则：
- 确保测试用例正确性
- 更新测试数据
- 修正测试逻辑
- 保持测试的有效性
```

### 分析决策树

```markdown
测试失败 → 分析错误信息
    ↓
是否符合预期业务行为？
    ↓                    ↓
   否                   是
    ↓                    ↓
修复业务逻辑          检查测试用例
    ↓                    ↓
重新测试              修复测试代码
    ↓                    ↓
验证修复效果          重新测试
```

## 修复策略

### 业务逻辑修复优先级

#### 1. 核心功能问题 (P0)

```markdown
问题类型：
- 主要功能无法使用
- 数据丢失或损坏
- 安全漏洞
- 系统崩溃

处理方式：
- 立即修复
- 全面测试
- 紧急发布
```

#### 2. 重要功能问题 (P1)

```markdown
问题类型：
- 功能部分异常
- 性能显著下降
- 用户体验问题
- 兼容性问题

处理方式：
- 优先修复
- 充分测试
- 计划发布
```

#### 3. 一般功能问题 (P2)

```markdown
问题类型：
- 边缘功能异常
- 轻微性能问题
- 界面显示问题
- 非关键路径错误

处理方式：
- 排期修复
- 常规测试
- 正常发布
```

### 修复验证流程

```markdown
修复步骤：
1. 问题根因分析
2. 制定修复方案
3. 实施代码修改
4. 单元测试验证
5. 集成测试验证
6. 回归测试确认
7. 性能影响评估
```

## 微信小程序测试要点

### 离线功能测试

```markdown
测试场景：
- 网络断开时的功能可用性
- 本地数据访问正确性
- 离线状态下的用户体验
- 网络恢复后的数据同步

验证标准：
- 核心功能离线可用
- 数据一致性保证
- 用户操作流畅性
- 错误提示友好性
```

### 分包加载测试

```markdown
测试场景：
- 分包按需加载
- 跨包功能调用
- 分包加载失败处理
- 预加载机制验证

验证标准：
- 分包大小符合限制
- 加载时间可接受
- 失败有降级方案
- 用户感知最小化
```

### 性能测试

```markdown
测试指标：
- 启动时间 < 3秒
- 页面切换 < 300ms
- 内存使用 < 限制值
- CPU使用率合理

测试方法：
- 真机测试
- 多设备验证
- 长时间运行测试
- 压力测试
```

## 测试报告格式

### 测试执行报告

```markdown
# 测试执行报告

## 测试概况
- 测试时间：[日期时间]
- 测试环境：[环境描述]
- 测试范围：[测试范围]
- 执行人员：[执行人]

## 测试结果统计
- 总测试用例数：[X]
- 通过用例数：[Y]
- 失败用例数：[Z]
- 通过率：[Y/X * 100%]

## 失败用例分析
### 用例1：[用例名称]
- 失败原因：[原因分析]
- 问题分类：[业务逻辑/测试代码]
- 修复方案：[修复计划]
- 优先级：[P0/P1/P2]

## 修复记录
### 修复1：[问题描述]
- 修复前状态：[状态描述]
- 修复方案：[方案说明]
- 修复后验证：[验证结果]
- 影响评估：[影响范围]
```

## 质量标准

### 测试通过标准

- ✅ 所有单元测试通过
- ✅ 所有集成测试通过
- ✅ 核心功能测试通过
- ✅ 性能指标达标
- ✅ 兼容性测试通过

### 代码质量标准

- ✅ 业务逻辑正确
- ✅ 异常处理完善
- ✅ 边界条件考虑
- ✅ 性能满足要求
- ✅ 安全性得到保障

## 自动化支持

### 持续集成

```markdown
自动化流程：
1. 代码提交触发
2. 自动构建项目
3. 执行测试套件
4. 生成测试报告
5. 通知相关人员
```

### 测试工具

```markdown
推荐工具：
- 单元测试：Jest, Mocha
- 集成测试：Cypress, Playwright
- 性能测试：Lighthouse, WebPageTest
- 代码覆盖率：Istanbul, NYC
```

## 常见问题处理

### 测试环境问题

```markdown
问题类型：
- 依赖服务不可用
- 测试数据不一致
- 配置文件错误
- 权限问题

解决方案：
- 检查服务状态
- 重置测试数据
- 验证配置正确性
- 确认权限设置
```

### 测试数据问题

```markdown
问题类型：
- 测试数据过期
- 数据格式变更
- 数据量不足
- 边界数据缺失

解决方案：
- 更新测试数据
- 适配新格式
- 补充测试用例
- 添加边界测试
```

## 成功指标

- 🎯 测试通过率：100%
- ⚡ 问题修复效率：高
- 🔍 问题分析准确性：准确
- 🛡️ 代码质量：优秀
- 📈 系统稳定性：稳定

## 最佳实践

### 测试驱动开发

1. **先写测试**：明确功能预期
2. **实现功能**：满足测试要求
3. **重构优化**：保持测试通过
4. **持续验证**：确保质量稳定

### 问题修复原则

1. **理解问题本质**：不只看表象
2. **修复根本原因**：避免症状修复
3. **验证修复效果**：确保问题解决
4. **防止问题复现**：加强预防机制

## 注意事项

1. **优先级明确**：业务逻辑问题优先于测试代码问题
2. **修复目标正确**：解决实际问题，不是为了通过测试
3. **全面验证**：修复后要进行完整的回归测试
4. **文档同步**：及时更新相关文档和注释
5. **经验总结**：记录问题和解决方案，避免重复

---

**记住：测试是质量的守护者，修复是问题的终结者。好的测试发现问题，好的修复解决问题。**
